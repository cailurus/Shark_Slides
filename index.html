<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Introduction to Shark(SQL/Hive on Spark)</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.min.css">
		<link rel="stylesheet" href="css/theme/default.css" id="theme">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- If the query includes 'print-pdf', use the PDF print sheet -->
		<script>
			document.write( '<link rel="stylesheet" href="css/print/' + ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">

				<section>
					<h2>Introduction to Shark</h2>
					<h3>SQL and Rich Analytics at Scale</h3>
					<p>
						Reported by <a href="http://xiaoxiongmao.me">Jinyang Zhou</a> / <a href="http://twitter.com/ailurus1991">@ailurus1991</a>
					</p>
				</section>

				<section>
					<h2>What is Spark?</h2>
					<p>
						<strong>NOT a modified version of Hadoop</strong>
					</p>
					<p>
						<strong>Separate, fast, MapReduce-link engine</strong>
					</p>
					<ul>
						<li class="fragment">In-memory data storage for very fast iterative queries</li>
						<li class="fragment">General execution graphs and powerful optimizations</li>
						<li class="fragment">Up to 100x faster than Hadoop MapReduce</li>
					</ul>
					<p></p>
					<p>
						<strong>Compatible with Hadoop's storage APIs</strong>
					</p>
					<ul>
						<li class="fragment">Can read/write to any Hadoop-supported system, including HDFS, HBase, SequenceFiles, etc</li>
					</ul>
					<aside class="notes">
						Oh hey, these are some notes. They'll be hidden in your presentation, but you can see them if you open the speaker notes window (hit 's' on your keyboard).
					</aside>
				</section>

				<section>
					<h2>What is Shark?</h2>
					<ul>
						<li><strong>A SQL analytics engine built on top of Spark</strong></li>
						<li><strong>Compatible with Apache Hive data, metastores, and queries(HiveQL, UDFs, etc)</strong></li>
						<li><strong>Similar speedups of up to 100x</strong></li>
					</ul>
				</section>

				<section>
					<section>
					<h2>Adoption</h2>
					<ul>
						<li><strong>In use of Yahoo!, Foursquare, Berkeley, Princetion & many others(possibly Taobao, Netease)</strong></li>
						<li><strong>600+ member meetup, 800+ watcherson Github</strong></li>
						<li><strong>30+ contributors</strong></li>
					</ul>	
					</section>
					<section>
						<img width="981" height="452" src="pic/douban.png">
					</section>
				</section>
				<!-- Example of nested vertical slides -->

				<section>
					<h2>This Talk</h2>
					<ul>
						<li><strong>Hadoop & MapReduce</strong></li>
						<li>Spark</li>
						<li>Shark: SQL on Spark</li>
						<li>Why is Hadoop Mapreduce slow?</li>
					</ul>
				</section>

				<section>
					<section>
						<p>How do you scale up applications to PBs of data?</p>
					</section>
					<section>
						<img width="157" height="186" src="pic/2.png">
						<p>I can use hundreds or thousands of machines!</p>
					</section>
					<section>
						<img width="130" height="128" src="pic/3.png">
						<p>But distributed programming is hard(task scheduling, data synchronization, machines failures)</p>
					</section>
				</section>

				<section>
					<h2>MapReduce</h2>
					<p><strong>Programming model:</strong> simple abstraction(i.e. map and reduce) inspired by functional programming</p>
					<p><strong>Execution engine:</strong> runs on thousands of commodity machines.</p>
				</section>

				<section>
					<h2>Hadoop</h2>
					<p><strong>Hadoop Distributed File System(HDFS)</strong></p>
					<ul>
						<li class="fragment">A distributed file system modeled after Google File System</li>
					</ul>
					<p><strong>Hadoop MapReduce(aka MapRed, MR)</strong></p>
					<p><strong>Many other related projects such as Hive(SQL on Hadoop)</strong></p>
				</section>

				<section>
					<h2>Hive</h2>
					<p><strong>A data warehouse</strong></p>
					<ul>
						<li class="fragment">initially developed by Facebook</li>
						<li class="fragment">puts structure onto HDFS data(schema-on-read)</li>
						<li class="fragment">compiles HiveQL queries into MapReudce jobs</li>
						<li class="fragment">flexible and extensible: support UDFs, scripts, custom serializers, storage formats</li>
					</ul>
					<p><strong>Popular</strong></p>
					<ul>
						<li class="fragment">90+% of Facebook Hadoop jobs generated by Hive</li>
					</ul>
					<p><strong>OLTP(serving) vs OLAP (analytics)</strong></p>
				</section>

				<section>
					<section>
						<h2>Dterminism & Idempotence</h2>
						<p><strong>Map and reduce functions are:</strong></p>
						<ul>
							<li>deterministic</li>
							<li>side-effect free</li>
						</ul>
						<p><strong>Tasks are thus idempotent:</strong></p>
						<ul>
							<li>Rerunning them gets you the same result</li>
						</ul>	
					</section>
					<section>
						<h2>Dterminism & Idempotence</h2>
						<p><strong>Fault-tolerance:</strong></p>
						<ul>
							<li>Rerun tasks originally schedualed on failed nodes</li>
						</ul>
						<p><strong>Straggers:</strong></p>
						<ul>
							<li>Rerun tasks originally schedualed on slow nodes</li>
						</ul>	
					</section>
				</section>

				<!-- Spark part-->
				<section>
					<h2>This Talk</h2>
					<ul>
						<li>Hadoop & MapReduce</li>
						<li><strong>Spark</strong></li>
						<li>Shark: SQL on Spark</li>
						<li>Why is Hadoop Mapreduce slow?</li>
					</ul>
				</section>

				<section>
					<section>
						<h3>Why go Beyond MapReduce?</h3>
						<p>MapReduce simplified big data analysis by giving a reliable programming model for large clusters</p>
						<p>But as soon as it got popular, users wanted:</p>
						<ul>
							<li class="fragment">More <strong>complex</strong>, multi-stage applications</li>
							<li class="fragment">More <strong>interactive</strong>, ad-hoc queries</li>
						</ul>	
					</section>
					<section>
						<p>Complex jobs and interactive queries both need one thing that MapReduce lacks:</p>
						<p class="fragment">Efficient primitives for <strong>data sharing</strong></p>
						<img class="fragment" width="872" height="254" src="pic/dshare.png">
					</section>
					<section>
						<p>In MapReduce, the only way to share data across jobs is stable storage(e.g. HDFS)</p>
						<P class="fragment highlight-red"><strong>SLOW!</strong></P>
					</section>
				</section>

				<section>
					<h2>Solution</h2>
					<p><strong>Resilient Distributed Datasets(RDDs)</strong></p>
					<ul>
						<li class="fragment">Distributed collections of objects that can be stored in memory for fast reuse</li>
						<li class="fragment">Automatically recover lost data on failure</li>
						<li class="fragment">Support a wide range of applications</li>
					</ul>
				</section>

				<section>
					<section>
						<h2>Programming Model</h2>
						<p>Resilient distributed datasets(RDDs)</p>
						<ul>
							<li class="fragment">Immutable, partitioned collections of objects</li>
							<li class="fragment">Can be cached in memory for effcient reuse</li>
						</ul>
						<p></p>
						<p>Transformations(e.g. map, filter, groupBy, join)</p>
						<ul>
							<li class="fragment">Build RDDs from other RDDs</li>
						</ul>
						<p></p>
						<p>Actions(e.g. count, collect, save)</p>
						<ul>
							<li class="fragment">Return a result or write it to storage</li>
						</ul>
					</section>
				</section>

				<section>
					<section>
						<h2>Fault Tolerance</h2>
						<p>RDDs	track the series of	transformations	used to	build	them (their	lineage) to	recompute lost data</p>
					</section>
					<section>
						<h2>Fault Recovery Results</h2>
						<img width="809" height="389" src="pic/fault.png">

					</section>
					<section>
						<h2>Tradeoff Space</h2>
						<img width="836" height="477" src="pic/tradeoff.png">

					</section>
					<section>
						<h2>Behavior with Not Enough RAM</h2>
						<img width="846" height="439" src="pic/ram.png">
					</section>
					<section>
						<h2>Logistic Regression Performance</h2>
						<img width="901" height="436" src="pic/logistic.png">
					</section>
				</section>

				<section>
					<section>
						<h2>Implementation</h2>
						<p>Use	Mesos/YARN	to	share	resources	with	Hadoop	&	other	frameworks</p>
						<p>Can	access	any	Hadoop	input	source	(HDFS,	S3,	…)</p>
						<p>20k lines of code</p>
						<img width="415" height="229" src="pic/sharkimp.png">

					</section>
					<section>
						<h2>User Applications</h2>
						<ul>
							<li>In-memory	analytics	&	anomaly	detection	(Conviva) </li>
							<li>Interactive	queries	on	data	streams	(Quantiﬁnd)	</li>
							<li>Exploratory	log	analysis	(Foursquare)	</li>
							<li>Traffic	estimation	w/	GPS	data	(Mobile	Millennium)	</li>
							<li>Twitter	spam	classiﬁcation	(Monarch)</li>
						</ul>
					</section>
					<section>
						<h2>Conviva GeoReport</h2>
						<img width="881" height="253" src="pic/conviva.png">
						<p>Group	aggregations	on	many	keys	w/	same	ﬁlter	</p>
						<p>40×	gain	over	Hive	from	avoiding	repeated	reading,	deserialization	and	ﬁltering</p>
					</section>
				</section>

				<!-- Spark part-->
				<section>
					<h2>This Talk</h2>
					<ul>
						<li>Hadoop & MapReduce</li>
						<li>Spark</li>
						<li><strong>Shark: SQL on Spark</strong></li>
						<li>Why is Hadoop Mapreduce slow?</li>
					</ul>
				</section>

				<section>
					<section>
						<h2>Challenges</h2>
						<ul>
							<li>Data volumes expanding</li>
							<li>Faults and stragglers complicate parallel database design</li>
							<li>Low-latency, interactivity</li>
						</ul>
					</section>
					<section>
						<h2>MPP Databases</h2>
						<ul>
							<li>Vertica, SAP HANA, Teradata, Google Dremel...</li>
							<li class="fragment highlight-green">Fast!</li>
							<li class="fragment highlight-red">Generally not fault-tolerant; challenging for long running queries as clusters scale up.</li>
							<li class="fragment highlight-red">Lack rich analytics such as ML and Graph algorithms.</li>
						</ul>
					</section>
					<section>
						<h2>MapReduce</h2>
						<ul>
							<li>Apache Hive, Google Tenzing, Turn Cheetah...</li>
							<li  class="fragment highlight-green">Deterministic, idempotent tasks: enables fine-grained fault-tolerance and resouce sharing.</li>
							<li  class="fragment highlight-green">Expressive ML algorithms.</li>
							<li  class="fragment highlight-red">High-latency, dismissed for interactive workloads.</li>
						</ul>
					</section>
				</section>

				<section>
					<section>
						<h2>Shark</h2>
						<p><strong>A data warehouse that</strong></p>
						<ul>
							<li>builds on Spark,</li>
							<li>scals out and is fault-tolerance,</li>
							<li>supports low-latency, interactive queries through in-memory computation,</li>
							<li>supports both SQL and complex analytics,</li>
							<li>is compatible with Apache Hive(storage, serdes, UDFs, types, metadata).</li>
						</ul>
					</section>
					<section>
						<h2>Hive Architecture</h2>
						<img width="839" height="470" src="pic/hive.png">

					</section>
					<section>
						<h2>Shark Architecture</h2>
						<img width="823" height="468" src="pic/shark.png">

					</section>
					<section>
						<h2>Engine Features</h2>
						<ul>
							<li>Columnar Memory Store</li>
							<li>ML Integration</li>
							<li>Partial DAG Execution</li>
							<li>Data Co-partitioning</li>
							<li>Partition Pruning based on Range Statistics</li>
						</ul>
					</section>
					<section>
						<h2>Efficient In-Memory Storage</h2>
						<p>Simply caching Hive records as Java objects is inefficient due to high per-object overhead</p>
						<p>Instead, Shark employs column-oriented storage using <strong>arrays of primitive types.</strong></p>
						<img width="628" height="244" src="pic/storage.png">

					</section>
					<section>
						<p><strong>Benefit:</strong> similarly compact size to serialized data, but>5x faster to access</p>
					</section>
					<section>
						<h2>ML Integration</h2>
						<ul>
							<li>Uniﬁed	system	for	query	processing	and	machine	learning</li>
							<li>Query	processing	and	ML	share	the	same	set	of	workers	and	caches</li>
						</ul>
					</section>
					<section>
						<h2>Performance</h2>
						<img width="887" height="491" src="pic/sharkper.png">

					</section>
				</section>

				<!-- Spark part-->
				<section>
					<h2>This Talk</h2>
					<ul>
						<li>Hadoop & MapReduce</li>
						<li>Spark</li>
						<li>Shark: SQL on Spark</li>
						<li><strong>Why is Hadoop Mapreduce slow?</strong></li>
					</ul>
				</section>

				<section>
					<h2>Why are previous MR-based systems slow?</h2>
					<ul>
						<li>Disk-based intermediate outputs.</li>
						<li>Inferior data format and layout(no control of data co-partitioning).</li>
						<li>Execution strategies (lack of optimization based on data statistics).</li>
						<li>Task scheduling and launch overhead!</li>
					</ul>
				</section>
				<section>
					<section>
						<h2>Task Launch Overhead</h2>
						<p><strong>Hadoop uses heartbeat to communicate scheduling decisions.</strong></p>
						<p><strong>Task launch delay 5-10 seconds.</strong></p>
						<p><strong>Spark uses an event-driven architecture and can launch tasks in 5ms</strong></p>
						<ul>
							<li>better parallelism</li>
							<li>easier straggler mitigration</li>
							<li>multi-tenancy resouce sharing</li>
						</ul>
					</section>
					<section>
						<h2>Task Launch Overhead</h2>
						<img width="880" height="355" src="pic/overhead.png">

					</section>
				</section>

				<section>
					<h1>THE END</h1>
				</section>

			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.min.js"></script>

		<script>

			// Full list of configuration options available here:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				theme: Reveal.getQueryHash().theme || 'serif', // available themes are in /css/theme
				transition: Reveal.getQueryHash().transition || 'zoom', // default/cube/page/concave/zoom/linear/fade/none

				// Optional libraries used to extend on reveal.js
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/showdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
					// { src: 'plugin/search/search.js', async: true, condition: function() { return !!document.body.classList; } }
					// { src: 'plugin/remotes/remotes.js', async: true, condition: function() { return !!document.body.classList; } }
				]
			});

		</script>

	</body>
</html>
